# -*- coding: utf-8 -*-
"""kimchi-model.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/144xEF5Mg4BtO7bZhCRXODbP2BsGaBxnD

### Kimchi Model Notebook
"""

import pandas as pd
import numpy as np

from sklearn.linear_model import LinearRegression
import sklearn.metrics as metrics
from sklearn.metrics import mean_absolute_percentage_error

from sklearn.preprocessing import RobustScaler
from sklearn.neural_network import MLPRegressor

"""### Upload Data"""

data = pd.read_excel("/content/Kimchi_dataset.xlsx")

df = data.copy()

"""### Create date columns"""

def get_date_features(df):
    """
    This function creates day and month feature from Date column.
    """
    df['month'] = df['Date'].dt.month
    df['day'] = df['Date'].dt.day
    # df.drop(columns=['Date'], inplace = True)

    return df

df = get_date_features(df)

"""### Fill null values"""

def fill_by_grp_mean(df, column):
  """
  Fill numeric column by each region groups mean value.
  """
  df[column] = df.groupby(['Region'])[column]\
      .transform(lambda x: x.fillna(x.mean()))
  return df

df = fill_by_grp_mean(df, "Total Volume")
df = fill_by_grp_mean(df, "Price")

"""### Get Dummies for Categorical Columns"""

df = pd.get_dummies(df, prefix=['Region'])

"""### Split Data"""

def split_train_test(df):
    """
    This function split df to train test sets.
    Return: 
      price as a y tra≈ün or test.
      last 2 weeks data without price as a test period.
      firts 10 weeks data without price as a train period.
    """
    df = df.set_index('Date') 
    X_train = df[df.index <="2018-03-15"].drop(columns = ["Price"])
    X_test = df[df.index >="2018-03-15"].drop(columns = ["Price"])

    y_train = df[df.index <="2018-03-15"]["Price"].copy()
    y_test = df[df.index>="2018-03-15"]["Price"].copy()

    print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)
    
    return X_train, X_test, y_train, y_test

X_train, X_test, y_train, y_test = split_train_test(df)

"""### Scale Categorical Columns"""

# Define scaler.
scaler = RobustScaler()

# Fit train and transform on test. we dont want data leakage.
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

"""### Run MLP Model"""

mlp = MLPRegressor(random_state=1, max_iter=500).fit(X_train, y_train)

mlp_pred = mlp.predict(X_test_scaled)

"""### Batch result predictions"""

mape = mean_absolute_percentage_error(y_test, mlp_pred)
print("Result with MAPE score: {}".format(mape))

result = data[data["Date"] >="2018-03-15"]
result["prediction"] = mlp_pred.copy()

result

